{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_data_size):\n",
    "    '''\n",
    "    Split data into test and training datasets.\n",
    "\n",
    "    INPUT\n",
    "        X: NumPy array of arrays\n",
    "        y: Pandas series, which are the labels for input array X\n",
    "        test_data_size: size of test/train split. Value from 0 to 1\n",
    "\n",
    "    OUPUT\n",
    "        Four arrays: X_train, X_test, y_train, and y_test\n",
    "    '''\n",
    "    return train_test_split(X, y, test_size=test_data_size, random_state=42)\n",
    "\n",
    "\n",
    "def reshape_data(arr, img_rows, img_cols, channels):\n",
    "    '''\n",
    "    Reshapes the data into format for CNN.\n",
    "\n",
    "    INPUT\n",
    "        arr: Array of NumPy arrays.\n",
    "        img_rows: Image height\n",
    "        img_cols: Image width\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "\n",
    "    OUTPUT\n",
    "        Reshaped array of NumPy arrays.\n",
    "    '''\n",
    "    return arr.reshape(arr.shape[0], img_rows, img_cols, channels)\n",
    "\n",
    "def cnn_model(train_gen, train_steps, val_gen, val_steps, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes, nb_gpus):\n",
    "    '''\n",
    "    Define and run the Convolutional Neural Network\n",
    "\n",
    "    INPUT\n",
    "        X_train: Array of NumPy arrays\n",
    "        X_test: Array of NumPy arrays\n",
    "        y_train: Array of labels\n",
    "        y_test: Array of labels\n",
    "        kernel_size: Initial size of kernel\n",
    "        nb_filters: Initial number of filters\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "        nb_epoch: Number of epochs\n",
    "        batch_size: Batch size for the model\n",
    "        nb_classes: Number of classes for classification\n",
    "\n",
    "    OUTPUT\n",
    "        Fitted CNN model\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    '''\n",
    "    First set of three layers\n",
    "    Image size: 256 x 256\n",
    "    nb_filters = 32\n",
    "    kernel_size = (2,2)\n",
    "    '''\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     strides=1,\n",
    "                     input_shape=(img_rows, img_cols, channels)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    '''\n",
    "    Second set of three layers\n",
    "    Image Size: 128 x 128\n",
    "    nb_filters = 64\n",
    "    kernel_size = 4,4\n",
    "    '''\n",
    "\n",
    "    nb_filters = 64\n",
    "    kernel_size = (4, 4)\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    # model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    '''\n",
    "    Third set of three layers\n",
    "    Image Size: 64 x 64\n",
    "    nb_filters = 128\n",
    "    kernel_size = 8,8\n",
    "    '''\n",
    "\n",
    "    nb_filters = 128\n",
    "    kernel_size = (8, 8)\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    # model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(12, 12)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(\"Model flattened out to: \", model.output_shape)\n",
    "\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    \n",
    "    model_name = 'ChestX'\n",
    "    checkpoint = ModelCheckpoint(model_name+'/'+model_name+'.h5', monitor='val_loss', verbose=2, save_best_only=True, mode='auto')\n",
    "    tensorboard = TensorBoard(log_dir=model_name, batch_size=batch_size, write_graph=True, write_images=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='auto')\n",
    "    cvslogger = keras.callbacks.CSVLogger(model_name+'/'+model_name+'.csv', separator=',', append=True)\n",
    "\n",
    "    callbacks = [checkpoint, reduce_lr, cvslogger, tensorboard, earlystop]\n",
    "    \n",
    "    #stop = EarlyStopping(monitor='acc',\n",
    "                         #min_delta=0.001,atience=2,\n",
    "                         #verbose=0,\n",
    "                         #mode='auto')\n",
    "\n",
    "    #tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    #checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "    #model.fit_generator(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "     #         verbose=1,\n",
    "      #        validation_split=0.2,\n",
    "       #       class_weight='auto',\n",
    "       #       callbacks=[EarlyStopping(monitor='val_loss',patience=3),checkpointer])\n",
    "    model.fit_generator(train_gen, train_steps, epochs=nb_epoch, verbose=1, \n",
    "                    max_queue_size=2, validation_data=val_gen, \n",
    "                    validation_steps=val_steps, shuffle=True,\n",
    "                    workers=1, use_multiprocessing= False, \n",
    "                    initial_epoch=0, callbacks=callbacks)\n",
    "    \n",
    "    return model  \n",
    "#callbacks=[stop, tensor_board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data_X, data_y, batch_size):\n",
    "    indexes = np.array(range(len(data_y)))\n",
    "    n = len(indexes)\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        np.random.shuffle(indexes)\n",
    "        while batch_start < n:\n",
    "            index = []\n",
    "            batch_y = []\n",
    "            y = []\n",
    "            index = indexes[batch_start:batch_end]\n",
    "            batch_x = np.array([data_X[i] for i in index])\n",
    "            batch_y = np.array([data_y[i] for i in index])\n",
    "            yield batch_x, batch_y\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    batch_size = 100\n",
    "    nb_classes = 2\n",
    "    nb_epoch = 2\n",
    "    nb_gpus = 8\n",
    "    img_rows, img_cols = 256,256\n",
    "    channels = 1\n",
    "    nb_filters = 32\n",
    "    kernel_size = (2, 2)\n",
    "\n",
    "    # Import data\n",
    "    labels = pd.read_csv(\"sample_labels.csv\")\n",
    "    X = np.load(\"X_sample.npy\")\n",
    "    y = labels.Finding_Labels\n",
    "    # y = np.array(pd.get_dummies(y))\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #y = label_encoder.fit_transform(y)\n",
    "    y = y.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96084, 256, 256)\n",
      "(96084, 1)\n"
     ]
    }
   ],
   "source": [
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train/val/test datasets\n",
      "(61493, 256, 256)\n",
      "(61493, 1)\n",
      "(19217, 256, 256)\n",
      "(19217, 1)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Splitting data into train/val/test datasets\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping Data\n",
      "('X_train Shape: ', (61493, 256, 256, 1))\n",
      "('X_test Shape: ', (19217, 256, 256, 1))\n",
      "('X_val Shape:', (15374, 256, 256, 1))\n"
     ]
    }
   ],
   "source": [
    "    print(\"Reshaping Data\")\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, channels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, channels)\n",
    "    X_val = X_val.reshape(X_val.shape[0],img_rows, img_cols, channels)\n",
    "    print(\"X_train Shape: \", X_train.shape)\n",
    "    print(\"X_test Shape: \", X_test.shape)\n",
    "    print(\"X_val Shape:\", X_val.shape)\n",
    "\n",
    "    input_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #X_train = X_train[1:70000]\n",
    "    #y_train = y_train[1:70000]\n",
    "    #X_test = X_test[1:10000]\n",
    "    #y_test = y_test[1:10000]\n",
    "    #print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a8bc65e3d77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#X_test = X_test/255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/np_utils.pyc\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "    #print(\"Normalizing Data\")\n",
    "    #X_train = X_train.astype(np.float32)\n",
    "    #X_test = X_test.astype(np.float32)\n",
    "    #X_val = X_val.astype(np.float32)\n",
    "    #X_train = X_train/255\n",
    "    #X_test = X_test/255\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "    print(\"y_train Shape: \", y_train.shape)\n",
    "    print(\"y_test Shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_gen = batch_generator(X_train, y_train, batch_size)\n",
    "    val_gen = batch_generator(X_val, y_val, batch_size)\n",
    "    test_gen = batch_generator(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_steps = int(len(y_train)//batch_size)\n",
    "    val_steps = int(len(y_test)//batch_size)\n",
    "\n",
    "    #model = cnn_model(X_train, y_train, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes, nb_gpus)\n",
    "    model = cnn_model(train_gen, train_steps,val_gen,val_steps, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes, nb_gpus)\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    X_test, y_test = test_gen.next()\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"Predicting\")\n",
    "    X_test, y_test = test_gen.next()\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
